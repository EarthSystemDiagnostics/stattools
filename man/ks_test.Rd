% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/stattest-functions.R
\name{ks_test}
\alias{ks_test}
\title{Kolmogorov-Smirnov Test for autocorrelated data}
\source{
\code{stats:::ks.test.default}
}
\usage{
ks_test(
  x,
  y,
  a1.x = 0,
  a1.y = 0,
  alternative = c("two.sided", "less", "greater"),
  exact = NULL,
  simulate.p.value = FALSE,
  B = 2000
)
}
\arguments{
\item{x}{a numeric vector of data values.}

\item{y}{a numeric vector of data values.}

\item{a1.x}{autocorrelation parameter at lag one of the data in \code{x}.}

\item{a1.y}{autocorrelation parameter at lag one of the data in \code{y}.}

\item{alternative}{indicates the alternative hypothesis and must be
    one of \code{"two.sided"} (default), \code{"less"}, or
    \code{"greater"}.  You can specify just the initial letter of the
    value, but the argument name must be given in full.
    See \sQuote{Details} for the meanings of the possible values.}

\item{exact}{\code{NULL} or a logical indicating whether an exact
    p-value should be computed.  See \sQuote{Details} for the meaning of
    \code{NULL}.}

\item{simulate.p.value}{a logical indicating whether to compute
    p-values by Monte Carlo simulation.}

\item{B}{an integer specifying the number of replicates used in the
    Monte Carlo test.}
}
\value{
see \code{?ks.test}.
}
\description{
Perform a two-sample Kolmogorov-Smirnov test accounting for autocorrelation
of the input data. This function is a modified version of the base R's
default two-sample \code{\link[stats]{ks.test}}, which treats autocorrelation
after Xu (2013) by resetting the number of observations to \code{n * (1 -a)},
where \code{n} are the original number of observations and \code{a} is the
user-supplied estimate of the data's autocorrelation parameter at lag
one. Note that this code is adapted from the default method of the ks.test
function, thus it can only test whether the data are from the same or from
different distributions and not test the data against a given cumulative
distribution function, nor can it be used with class \code{formula}.
}
\examples{

# Check the performance of the test on autocorrelated data

# This function Monte Carlo samples autocorrelated data series from an AR1
# process and runs the default ks test as well as the stattools ks_test to
# estimate the tests' rejection rates, i.e. the relative number of false
# positives where the tests reject the null hypothesis
estimateRejectionRate <- function(nobs, nr, a1.x, a1.y = a1.x) {

 # wrapper for random generation of AR1 series
 redNoise <- function(a1, n) {c(arima.sim(list(ar = a1), n))}

 # MC sampling of p values
 pval <- array(dim = c(2, nr))
 for (i in 1 : nr) {

   x <- redNoise(a1.x, nobs)
   y <- redNoise(a1.y, nobs)

   tmp1 <- ks.test(x, y)
   tmp2 <- ks_test(x, y, a1.x = a1.x, a1.y = a1.y)

   # count false positives
   if (tmp1$p.value <= 0.05) pval[1, i] <- 1 else pval[1, i] <- 0
   if (tmp2$p.value <= 0.05) pval[2, i] <- 1 else pval[2, i] <- 0

 }

 # return null hypothesis rejection rates (type I error)
 c(ks.test.default = sum(pval[1, ]) / nr,
   ks_test = sum(pval[2, ]) / nr)

}

# The expectation is a rejection rate of around 0.05; in the following
# examples we see that the default ks.test shows higher than expected
# rejection rates for autocorrelated data while the ks_test remedies this
# issue for identical autocorrelation...

estimateRejectionRate(1000, 1000, 0.5)
estimateRejectionRate(1000, 1000, 0.9)

# ..., however, it shows rejection rates > 0.05 if the autoccorelation is
# very different, for which the reason is unclear at the moment, with better
# rejection rates for small sample sizes

estimateRejectionRate(1000, 1000, 0.5, 0.6)
estimateRejectionRate(1000, 1000, 0.5, 0.8)
estimateRejectionRate(99, 1000, 0.5, 0.8)

}
\references{
Xu, X.: Methods in Hypothesis Testing, Markov Chain Monte Carlo and
  Neuroimaging Data Analysis, PhD thesis, Harvard University, Cambridge,
  Massachusetts, \url{http://nrs.harvard.edu/urn-3:HUL.InstRepos:11108711},
  2013.
}
\seealso{
\code{\link[stats]{ks.test}}
}
\author{
R Core Team, Thomas MÃ¼nch
}
